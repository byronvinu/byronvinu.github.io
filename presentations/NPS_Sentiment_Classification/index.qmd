---
title: "Sentiment Classification for NPS Data:" 
subtitle: "An Approach with Hybrid Models and Transfer Learning"
author: "Byron Vinueza"
date: "2025-12-18"
categories: ["Presentaciones","NLP","Deep Learning","NPS"]
description: "Exploraci贸n de t茅cnicas avanzadas de clasificaci贸n de sentimientos en datos de NPS utilizando modelos h铆bridos y aprendizaje por transferencia."
image: "img/wordcloud.png"
format:
  revealjs:
    theme: [default]
    slide-number: true
    chalkboard: true
    preview-links: auto
    logo: ""
    footer: "[byronvinu.rbind.io/](https://byronvinu.rbind.io/)" 
    transition: slide
    background-transition: fade
jupyter: python3
---

## Agenda {.smaller}
::: {.incremental}
::: {.columns}
::: {.column width="50%"}

1. **Introducci贸n y Contexto**
   - 驴Qu茅 es NPS?
   - Objetivos del proyecto

2. **Flujo del Proyecto**
   - Pipeline del procesamiento

3. **Distribuci贸n de clases**
   - Dataset y su distribuci贸n
   - T茅cnicas de balanceo.

:::
::: {.column width="50%"}
4. **Arquitecturas**
   - LSTM Bidireccional + Attention
   - Lematizaci贸n + Baseline
   - Modelo H铆brido
   - Fine-Tuning con BETO

5. **Resultados y Evaluaci贸n**
   - Comparaci贸n de t茅cnicas
   - M茅tricas de rendimiento

6. **Conclusiones y Recomendaciones**
   - Resumen de hallazgos

:::
:::
:::


# 驴QU ES NPS? {background-color="#1e3a8a" #what-is-nps .smaller}

## 驴Qu茅 es NPS? {.smaller}

::: {.columns}
::: {.column width="50%"}
**Net Promoter Score (NPS)**

- M茅trica de satisfacci贸n del cliente.
- Escala de 0 a 10
- Tres categor铆as:
  - **Detractores** (0-6)
  - **Pasivos** (7-8)
  - **Promotores** (9-10)
:::

::: {.column width="50%"}
```{python}
#| name: nps_distribution
#| echo: false
#| fig-align: center
import pandas as pd
import altair as alt

# Distribuci贸n NPS ordenada: 0-6, 7-8, 9-10
nps_data = pd.DataFrame({
    'Categor铆a': ['Detractor', 'Pasivo', 'Promotor'],
    'Descripci贸n': ['0-6', '7-8', '9-10'],
    'Orden': [1, 2, 3],
    'Color': ['#ef4444', '#f59e0b', '#10b981']
})

chart = alt.Chart(nps_data).mark_bar().encode(
    x=alt.X('Categor铆a:N', 
            title=None,
            sort=['Detractor', 'Pasivo', 'Promotor']),
    y=alt.Y('Descripci贸n:N', 
            title='Puntuaci贸n',
            sort=['9-10', '7-8', '0-6']),  # Invertido: de arriba (9-10) a abajo (0-6)
    color=alt.Color('Color:N', scale=None, legend=None),
    tooltip=['Categor铆a:N', 'Descripci贸n:N']
).properties(
    width=500,
    height=300,
    title='Categor铆as NPS'
)
chart

```
:::
:::

::: {.callout-tip icon=true}
## Importancia
- **Los comentarios de los clientes son fundamentales para entender las razones detr谩s de sus puntuaciones NPS.**
- **Mide la lealtad y satisfacci贸n del cliente, proporcionando insights valiosos para mejorar productos y servicios.**
:::


# OBJETIVOS {background-color="#38539dff" #objectives .smaller}

## Objetivos del Proyecto {.smaller}

:::{.incremental}

### Objetivo Principal

- **El objetivo es construir un modelo de clasificaci贸n robusto y generalizable con alta sensibilidad (Recall) para la clase Detractor, minimizando los falsos negativos y apoyando el flujo de trabajo de resoluci贸n de quejas.**

### Objetivos Espec铆ficos

- Explorar t茅cnicas avanzadas de procesamiento de lenguaje natural (NLP) para mejorar la precisi贸n de la clasificaci贸n de sentimientos en datos de NPS.

- Implementar y comparar modelos h铆bridos y enfoques de aprendizaje por transferencia para optimizar el rendimiento del modelo.

- Evaluar el impacto de diferentes t茅cnicas de balanceo de datos en la sensibilidad del modelo hacia la clase Detractor.

:::

# FLUJO DEL PROYECTO {background-color="#1e3a8a" #project-flow .smaller}

## Pipeline de Procesamiento

::: {.columns}
::: {.column width="30%"}
```{mermaid}
%%{init: { "flowchart": { "nodeSpacing": 15, "rankSpacing": 20 }}}%%
flowchart TD 
    A["Extracci贸n de Datos"] --> B["Preprocesamiento GPT"]
    B --> C["An谩lisis Exploratorio "]
    C --> D["Modelo  - Arquitectura "]
    D --> E["Entrenamiento
    del Modelo"]
    E --> F["Evaluaci贸n y 
    Validaci贸n"]
    F --> D
    
    style A fill:#e0e7ff,stroke:#4f46e5,stroke-width:1px
    style B fill:#fef3c7,stroke:#f59e0b,stroke-width:1px
    style C fill:#dbeafe,stroke:#3b82f6,stroke-width:1px
    style D fill:#e0f2fe,stroke:#0ea5e9,stroke-width:1px
    style E fill:#dcfce7,stroke:#10b981,stroke-width:1px
    style F fill:#d1fae5,stroke:#059669,stroke-width:1px

```
:::

::: {.column width="70%"}

**Paso Clave: Preprocesamiento con IA**

-  **OpenAI GPT-3.5** para correcci贸n autom谩tica de texto
- 锔 Correcci贸n de ortograf铆a y gram谩tica

::: {.callout-note}
## Impacto del Preprocesamiento
- Mejor贸 significativamente la calidad de los datos de entrada antes del an谩lisis.
:::
:::
:::

# EXPLORACIN DE DATOS {background-color="#38539dff" #data-exploration .smaller}
## Distribuci贸n de clases {.smaller}

```{python}
#| name: nps_class_distribution
#| echo: false
#| fig-align: center
#| message: false
#| warning: false

import pandas as pd
import matplotlib as plt

# Cargar datos
data = pd.DataFrame({
    'T茅cnica': ['Sin balanceo', 'Undersampling', 'Oversampling', 'Hybrid (U=0.3,O=0.8)'],
    'Total': [69923, 10419, 181260, 47126],
    'Det': [3473, 3473, 60420, 14500],
    'Pasivo': [6030, 3473, 60420, 14500],
    'Promo': [60420, 3473, 60420, 18126]
})
# graficar para cada t茅cnica la distribuci贸n de clases, un grafico por cada t茅cnica
fig, ax = plt.pyplot.subplots(1, 4, figsize=(20, 5))
techniques = data['T茅cnica'].tolist()
for i, technique in enumerate(techniques):
    counts = [data.loc[i, 'Det'], data.loc[i, 'Pasivo'], data.loc[i, 'Promo']]
    ax[i].bar(['Detractor', 'Pasivo', 'Promotor'], counts, color=['#ef4444', '#f59e0b', '#10b981'])
    ax[i].set_title(f'Distribuci贸n de Clases - {technique}')
    ax[i].set_ylabel('')
plt.pyplot.tight_layout()
plt.pyplot.show()

```
<!-- salto de linea -->
<br>
<br>

```{python}
#| echo: false
#| message: false
#| label: tbl-nps-class-distribution
#| tbl-cap: "Distribuci贸n de clases por t茅cnica de balanceo"
#| fig-align: center

import pandas as pd  
from IPython.display import Markdown, display
data = {
    'T茅cnica': ['Sin balanceo', 'Undersampling', 'Oversampling', 'Hybrid (U=0.3,O=0.8)'],
    'Total': [69923, 10419, 181260, 47126],
    'Detractor': [3473, 3473, 60420, 14500],
    'Pasivo': [6030, 3473, 60420, 14500],
    'Promotor': [60420, 3473, 60420, 18126]
}
df = pd.DataFrame(data)
display(Markdown(df.to_markdown(index=False)))
```

# ARQUITECTURAS DE MODELOS  {background-color="#1e3a8a" #architectures .smaller}

## Baseline {.smaller}

![](img/modelo_baseline.png){fig-align="center" height="300px" width="600px"}

:::{.callout-tip icon=true}
## LSTM Bidireccional + Attention
- *Capa de embedding* El texto de entrada se convierte en vectores de embedding usando Word2Vec.
- *LSTM bidireccional* Captura dependencias contextuales en ambas direcciones
- *Mecanismo de atenci贸n* Permite al modelo enfocarse en palabras clave relevantes para la clasificaci贸n.
:::

## Resultados Baseline (Grid Search) {.smaller}
![](img/GridSearch_baseline.png){fig-align="center" height="600px" width="1200px"}

## M茅tricas Baseline {.smaller}
![](img/baseline_results.png){fig-align="center" height="600px" width="1200px"}


## Lematizaci贸n + Baseline {.smaller}
![](img/modelo_lema_baseline.png){fig-align="center" height="300px" width="600px"}

:::{.callout-tip icon=true}
## Lematizaci贸n + Baseline
- *Lematizaci贸n* Reduce las palabras a su forma base para disminuir la variabilidad.
- *Arquitectura Baseline* Se utiliza la misma arquitectura que el modelo baseline.
:::

## Grid Search Lematizaci贸n + Baseline {.smaller}
![](img/GridSearch_lemabaseline.png){fig-align="center" height="600px" width="1200px"}

## M茅tricas Lematizaci贸n + Baseline {.smaller}

![](img/lemabase_results.png){fig-align="center" height="600px" width="1200px"}

## Modelo H铆brido {.smaller}
![](img/hibrido_bert_embeding.png){fig-align="center" height="300px" width="600px"}

:::{.callout-tip icon=true}
## Modelo H铆brido  
- *Tokenizaci贸n*  del texto de entrada, mediante el tokenizador WordPiece espec铆fico de BETO.
- *Embeddings preentrenados*  utilizando BETO para capturar representaciones sem谩nticas ricas.
- *Arquitectura Baseline* Utiliza la misma arquitectura que el modelo baseline.
:::

## Comparaci贸n Baseline vs H铆brido {.smaller}

<!-- awesome table on quarto -->

| Aspecto | Baseline  | BERT H铆brido  |
|---------|---------------------|-------------------------|
| **Embeddings** | Aprendidos desde cero (128d) | **BERT preentrenado (768d)**  |
| **Modelado secuencial** | BiLSTM + Attention  | BiLSTM + Attention  |
| **Par谩metros BERT** | 0 | 110M (frozen, no entrenan) |
| **Par谩metros Entrenables** | ~4.2M | ~2.5M (LSTM+Attention+FC) |
| **Conocimiento previo** | No | **S铆 (Wikipedia, corpus espa帽ol)**  |
| **Velocidad entrenamiento** | R谩pido | Medio (forward de BERT + train LSTM) |


## M茅tricas H铆brido {.smaller}
![](img/hibrido_results.png){fig-align="center" height="600px" width="1200px"}

## Fine-Tuning con BETO {.smaller}
![](img/fine_tuning_beto.png){fig-align="center" height="300px" width="600px"}

:::{.callout-tip icon=true}
## Fine-Tuning con BETO
- *Tokenizaci贸n* del texto de entrada mediante el tokenizador WordPiece espec铆fico de BETO.
- *Modelo BETO completo* Se utiliza todo el modelo BETO, permitiendo que todos sus par谩metros se ajusten durante el entrenamiento.
:::

## M茅tricas Macro Fine-Tuning BETO {.smaller}

<!-- Como hacer la tabla mas peque帽a -->
<div style="font-size: 0.5em;">

| **T茅cnica**               | **F1**     | **Recall** | **Precision** |
| ------------------------- | ---------- | ---------- | ------------- |
| Sin Balanceo (LR = 2e-5)  | **0.8022** | 0.7880     | **0.8176**    |
| Sin Balanceo (LR = 5e-5)  | 0.7995     | 0.7856     | 0.8144        |
| Class Weights (LR = 2e-5) | 0.7939     | 0.7977     | 0.7904        |
| Class Weights (LR = 5e-5) | 0.7927     | 0.7999     | 0.7862        |
| H铆brido (LR = 2e-5)       | 0.7733     | 0.8063     | 0.7457        |
| H铆brido (LR = 5e-5)       | 0.7704     | 0.7982     | 0.7501        |
| Oversampling (LR = 5e-5)  | 0.7715     | 0.8049     | 0.7437        |
| Oversampling (LR = 2e-5)  | 0.7640     | 0.7895     | 0.7421        |
| Undersampling (LR = 5e-5) | 0.7692     | 0.8135     | 0.7392        |
| Undersampling (LR = 2e-5) | 0.7562     | **0.8218** | 0.7099        |
</div>

:::{.callout-tip icon=true}
## Observaciones Fine-Tuning BETO
- **Mejor F1 y Precisi贸n**: El modelo sin balanceo con una tasa de aprendizaje de 2e-5 logr贸 el mejor F1 (0.8022) y precisi贸n (0.8176).
- **Mejor Recall**: El modelo con undersampling y una tasa de aprendizaje de 2e-5 alcanz贸 el mejor recall (0.8218), crucial para identificar detractores, sin embargo, con una precisi贸n m谩s baja (0.7099)
- **Class Weights**: Los modelos con pesos de clase muestran un equilibrio entre recall y precisi贸n, siendo una buena opci贸n para balancear ambos aspectos.
:::

## M茅tricas Fine-Tuning BETO {.smaller}

<div style="font-size: 0.5em;">
| **M茅trica** | **Sin Balanceo (2e-5)** | **Sin Balanceo (5e-5)** | **Class Weights (2e-5)** | **Class Weights (5e-5)** |
| ----------- | ----------------------- | ----------------------- | ------------------------ | ------------------------ |
| F1 Prom     | 0.9785                  | 0.9783                  | 0.9765                   | 0.9762                   |
| F1 Pas      | 0.7052                  | 0.6979                  | 0.6910                   | 0.6839                   |
| F1 Det      | 0.7228                  | 0.7221                  | 0.7143                   | 0.7178                   |
| Rec. Prom   | 0.9836                  | 0.9834                  | 0.9745                   | 0.9748                   |
| Rec. Pas    | 0.6824                  | 0.6741                  | 0.7065                   | 0.6783                   |
| Rec. Det    | 0.6978                  | 0.6993                  | 0.7122                   | 0.7468                   |
| Prec. Prom  | 0.9735                  | 0.9733                  | 0.9786                   | 0.9777                   |
| Prec. Pas   | 0.7296                  | 0.7233                  | 0.6762                   | 0.6897                   |
| Prec. Det   | 0.7496                  | 0.7465                  | 0.7164                   | 0.6911                   |
</div>

:::{.callout-tip icon=true}
## Observaciones M茅tricas por Clase Fine-Tuning BETO
- **Desempe帽o por Clase**: El modelo sin balanceo muestra un desempe帽o significativamente superior en la clase Promotor en comparaci贸n con las otras clases.
- **Recall Detractor**: Los modelos con class weights mejoran el recall para la clase Detractor, lo cual es crucial para identificar clientes insatisfechos.
- **Precisi贸n Pasivo**: La precisi贸n para la clase Pasivo es consistentemente m谩s baja en todos los modelos, indicando un desaf铆o en clasificar correctamente esta categor铆a.
:::

# COMPARACIN DE MODELOS {background-color="#1e3a8a" #model-comparison .smaller}

## F1 entre arquitecturas {.smaller}
![](img/resumenF1.png){fig-align="center" height="300px" width="800px"}

:::{.callout-tip icon=true}
## Variaciones de F1
- **BETO Fine-Tuning**: Muestra la mejor puntuaci贸n F1 macro, destacando su eficacia en la clasificaci贸n de sentimientos en datos de NPS.
- **Modelos H铆bridos y Baseline**: Aunque no alcanzan el rendimiento de BETO, los modelos h铆bridos y baseline con lematizaci贸n ofrecen mejoras significativas sobre el baseline simple.
:::

## M茅tricas para fine-tuning BETO {.smaller}

:::{.columns}
::: {.column width="50%"}
![](img/heatmap_metricas.png){fig-align="center" height="250px" }
:::
::: {.column width="50%"}
![](img/confusion_matrix.png){fig-align="center" height="250px" }
:::
:::

:::{.callout-tip icon=true}
## An谩lisis de M茅tricas y Matriz de Confusi贸n
- **Heatmap de M茅tricas**: Permite visualizar el rendimiento detallado de cada modelo en t茅rminos de F1, Recall y Precisi贸n para cada clase.
- **Matriz de Confusi贸n**: Destaca la capacidad del modelo para clasificar correctamente las instancias, especialmente en la clase Detractor, que es crucial para el objetivo del proyecto.
:::

# CONCLUSIONES {background-color="#38539dff" #conclusions .smaller}

## Conclusiones  {.smaller}

:::{.incremental}

- El modelo Fine-Tuned Beto logr贸 un mayor performance que las otras arquitecturas en todas las m茅tricas evaluadas, alcanzando un mejor desempe帽o a nivel macro y por clase.

- El modelo Fine-Tuned BETO con Class Weights se establece como la alternativa m谩s adecuada para el despliegue, logrando el equilibrio 贸ptimo entre un alto Recall para la Clase Detractor (en l铆nea con el enfoque Omotenashi) y un rendimiento general estable.

- La lematizaci贸n no mostro mejoras en el desempe帽o del modelo baseline, sugiriendo que la reducci贸n de variabilidad en las palabras no siempre conduce a mejores resultados en tareas de clasificaci贸n de texto.

::: 

# BONUS: Aplicaci贸n con Reviews de Google {background-color="#1e3a8a" #practical-application .smaller}

## Aplicaci贸n Pr谩ctica {.smaller}

:::{.callout-tip icon=true}
## Detractor 
Text: No crean en las  opiniones est谩n borrando las malas rese帽as 1000 veces Metro el del condado nunca atiende aqu铆
Predicted label: DETRACTOR with confidence 0.9980
CALIFICACION: 1
:::

:::{.callout-tip icon=true}
## Promotor
Text: Excelente atenci贸n r谩pides en el mantenimiento vehicular
Predicted label: PROMOTOR with confidence 0.9957
CALIFICACION: 5
:::

:::{.callout-tip icon=true}
## Detractor
Text: Terrible la atenci贸n, da帽aron el radio del carro, la peor experiencia. No quiero volver m谩s nunca
Predicted label: DETRACTOR with confidence 0.9981
CALIFICACION: 1
:::

:::{.callout-tip icon=true}
## Pasivo
Text: Algo extra帽o, busc谩bamos el corolla cross,  de contado no puedes comprarlo porque no est谩 disponible, pero con su sistema "toyota siempre nuevo" ah铆 si. Es decir, prefieren que te endeudes para nunca terminar de pagar un auto en lugar de que te lo lleves a casa siendo completamente tuyo.
Predicted label: PASIVO with confidence 0.9664
CALIFICACION: 3
:::

## Distribuci贸n de predicciones {.smaller}

:::{.columns}
::: {.column width="50%"}
![](img/pred_google.png){fig-align="center" height="230px" }
:::
::: {.column width="50%"}
![](img/tablero_resenas.png){fig-align="center" height="230px" }
:::
:::

![](img/nps_google.png){fig-align="center" height="260px" width="600px"}

# GRACIAS! {background-color="#38539dff" #thank-you .smaller}
## 隆Gracias por su atenci贸n! {.smaller}